{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"commands_extensions/","text":"Execution Commands Extensions Version v2.0.0 introduced extension points in ExecutionCommand contract, allowing you to inject custom logic before and after a command's main execution. You can create reusable actions that automatically run at specific points in a command's lifecycle without modifying the command's core implementation. How It Works When an ExecutionCommand runs, it follows a strict lifecycle. If you provide pre_execute_actions and/or post_execute_actions to the command's constructor, they will be executed at their respective lifecycle stages, in the order they were provided. Command.run() \u251c\u2500\u2500 _log_input_params() \u251c\u2500\u2500 _validate() \u251c\u2500\u2500 **_pre_execute()** \u2190 Your extensions run here \u251c\u2500\u2500 _execute() \u2190 Main command logic \u251c\u2500\u2500 **_post_execute()** \u2190 Your extensions run here \u2514\u2500\u2500 _exit() Usage sample Sample dummy extensions for unit-testing are provided in this repository in test_command_extensions.py . You can find there OverrideParam1PreExt pre-execute action and OverrideResultPostExt post-execute action (although pre- and post- actions contract is the same). They are added to command in its constructor: cmd = SampleExtendableCommand(input_params=test_input_params, pre_execute_actions=[OverrideParam1PreExt()], post_execute_actions=[OverrideResultPostExt()]) New parameters in ExecutionCommand class Parameter Type Description Default pre_execute_actions List[ExecutionCommandExtension] Extensions to run before _execute() None post_execute_actions List[ExecutionCommandExtension] Extensions to run after _execute() None ExecutionCommandExtension Abstract Base Class The interface all extensions must implement. Method Returns Description with_command(command) ExecutionCommandExtension Injects the command and its context into the extension execute() None Abstract - Contains the extension's core logic Extensions inside _execute() Some commands might provide alternative extension points, e.g. - GithubRunPipeline and GitlabRunPipeline commands have extensions in form of PipelineDataImporter contract. These extensions will be specific to their respective commands, and invoked according to inner business logic of them, but they still might be shared across similar commands. In this case these extension points are described inside commands themselves.","title":"Execution Commands Extensions"},{"location":"commands_extensions/#execution-commands-extensions","text":"Version v2.0.0 introduced extension points in ExecutionCommand contract, allowing you to inject custom logic before and after a command's main execution. You can create reusable actions that automatically run at specific points in a command's lifecycle without modifying the command's core implementation.","title":"Execution Commands Extensions"},{"location":"commands_extensions/#how-it-works","text":"When an ExecutionCommand runs, it follows a strict lifecycle. If you provide pre_execute_actions and/or post_execute_actions to the command's constructor, they will be executed at their respective lifecycle stages, in the order they were provided. Command.run() \u251c\u2500\u2500 _log_input_params() \u251c\u2500\u2500 _validate() \u251c\u2500\u2500 **_pre_execute()** \u2190 Your extensions run here \u251c\u2500\u2500 _execute() \u2190 Main command logic \u251c\u2500\u2500 **_post_execute()** \u2190 Your extensions run here \u2514\u2500\u2500 _exit()","title":"How It Works"},{"location":"commands_extensions/#usage-sample","text":"Sample dummy extensions for unit-testing are provided in this repository in test_command_extensions.py . You can find there OverrideParam1PreExt pre-execute action and OverrideResultPostExt post-execute action (although pre- and post- actions contract is the same). They are added to command in its constructor: cmd = SampleExtendableCommand(input_params=test_input_params, pre_execute_actions=[OverrideParam1PreExt()], post_execute_actions=[OverrideResultPostExt()])","title":"Usage sample"},{"location":"commands_extensions/#new-parameters-in-executioncommand-class","text":"Parameter Type Description Default pre_execute_actions List[ExecutionCommandExtension] Extensions to run before _execute() None post_execute_actions List[ExecutionCommandExtension] Extensions to run after _execute() None","title":"New parameters in ExecutionCommand class"},{"location":"commands_extensions/#executioncommandextension-abstract-base-class","text":"The interface all extensions must implement. Method Returns Description with_command(command) ExecutionCommandExtension Injects the command and its context into the extension execute() None Abstract - Contains the extension's core logic","title":"ExecutionCommandExtension Abstract Base Class"},{"location":"commands_extensions/#extensions-inside-_execute","text":"Some commands might provide alternative extension points, e.g. - GithubRunPipeline and GitlabRunPipeline commands have extensions in form of PipelineDataImporter contract. These extensions will be specific to their respective commands, and invoked according to inner business logic of them, but they still might be shared across similar commands. In this case these extension points are described inside commands themselves.","title":"Extensions inside _execute()"},{"location":"maven_auth/","text":"Authorizing with maven-client (MavenArtifactSearcher) All existing maven repositories support basic authorization, the only difference is how you go about issuing their tokens. Authorization is required when accessing private repositories, and the same username/token pair could be used in Maven or Gradle There's also now another way of working with Maven and Generic repositories - ArtifactFinder client, that supports plug-ins for different providers, and separate Cloud Authentication/Credentials abstraction. JFrog Artifactory JFrog Artifactory supports basic password authentication, so you can just use your technical user's login/password pair params_jfrog = { \"username\": \"x_technical_user\", \"password\": os.getenv('JFROG_TECH_USER_PASSWORD'), \"registry_url\": \"http://192.168.225.129:8081/artifactory/test-mvn-repo\", } maven_searcher = MavenArtifactSearcher(params_jfrog.get(\"registry_url\")).with_artifactory(params_jfrog.get(\"username\"), params_jfrog.get(\"password\")) GitHub Packages To access Maven artifacts stored in GitHub Packages, you need to authenticate with your personal access token. Official documentation on this process is here But to recap, you need to go to your (or your technical user's) account settings: Settings -> Developer Settings -> Personal access tokens -> Tokens (classic) And Generate new token (classic) (token looks like ghp_..... ) GitHub doesn't have a single maven registry, but rather a registry per User/Organization. So for registry URL you need to use either https://maven.pkg.github.com/Netcracker/* (to navigate all repositories under specified user) or https://maven.pkg.github.com/Netcracker/certain_repo_name registry_connection_params_github = { \"username\": \"gh_tech_user_login\", \"password\": os.getenv('GH_ACCESS_TOKEN'), \"registry_url\": \"https://maven.pkg.github.com/Netcracker/*\", } Google Cloud GAR (Google Artifact Registry) Official documentation on this process is here You need to use service account key as a credential. So the process is: Create new Service Account with minimum required roles/permissions to access your Artifact Registry (e.g. \"Artifact Registry Reader\" role) Create new Service Account Key - and download it (it's a .json file) base64 encode this file to get your authentication token (e.g. base64 -w 0 your_key.json > encoded_key.txt ) username should be _json_key_base64 params_gcp = { \"username\": \"_json_key_base64\", \"password\": os.getenv('GAR_ACCESS_TOKEN'), \"registry_url\": \"https://LOCATION-maven.pkg.dev/PROJECT/REPOSITORY\", } maven_searcher = MavenArtifactSearcher(params_gcp.get(\"registry_url\")).with_gcp_artifact_registry({\"service_account_key\": params_gcp.get(\"password\")}, PROJECT, REGION, REPOSITORY) AWS Code Artifact Official AWS documentation is here You access Code Artifact repositories using special temporary token, but it's only valid for up to 12 hours. To use persistent credentials, this library provides utility helper AWSCodeArtifactHelper that can generate token for you using Access + Secret keys and your domain + region. You need to create an IAM User with required policies/permissions ( instructions here ) Get Access Key and Secret Key to this user, you'll need them to generate your temporary authorization token to Code Artifact params_aws = { \"username\": \"aws\", \"password\": AWSCodeArtifactHelper.get_authorization_token( os.getenv('AWS_ACCESS_KEY'), os.getenv('AWS_SECRET_KEY'), \"test-maven-domain\", \"us-east-1\" ), \"registry_url\": \"https://test-maven-domain-123.d.codeartifact.us-east-1.amazonaws.com/maven/test-maven-repo/\", } maven_searcher = MavenArtifactSearcher(params_aws.get(\"registry_url\")).with_aws_code_artifact(os.getenv('AWS_ACCESS_KEY'), os.getenv('AWS_SECRET_KEY'), DOMAIN, REGION, REPOSITORY)","title":"Maven"},{"location":"maven_auth/#authorizing-with-maven-client-mavenartifactsearcher","text":"All existing maven repositories support basic authorization, the only difference is how you go about issuing their tokens. Authorization is required when accessing private repositories, and the same username/token pair could be used in Maven or Gradle There's also now another way of working with Maven and Generic repositories - ArtifactFinder client, that supports plug-ins for different providers, and separate Cloud Authentication/Credentials abstraction.","title":"Authorizing with maven-client (MavenArtifactSearcher)"},{"location":"maven_auth/#jfrog-artifactory","text":"JFrog Artifactory supports basic password authentication, so you can just use your technical user's login/password pair params_jfrog = { \"username\": \"x_technical_user\", \"password\": os.getenv('JFROG_TECH_USER_PASSWORD'), \"registry_url\": \"http://192.168.225.129:8081/artifactory/test-mvn-repo\", } maven_searcher = MavenArtifactSearcher(params_jfrog.get(\"registry_url\")).with_artifactory(params_jfrog.get(\"username\"), params_jfrog.get(\"password\"))","title":"JFrog Artifactory"},{"location":"maven_auth/#github-packages","text":"To access Maven artifacts stored in GitHub Packages, you need to authenticate with your personal access token. Official documentation on this process is here But to recap, you need to go to your (or your technical user's) account settings: Settings -> Developer Settings -> Personal access tokens -> Tokens (classic) And Generate new token (classic) (token looks like ghp_..... ) GitHub doesn't have a single maven registry, but rather a registry per User/Organization. So for registry URL you need to use either https://maven.pkg.github.com/Netcracker/* (to navigate all repositories under specified user) or https://maven.pkg.github.com/Netcracker/certain_repo_name registry_connection_params_github = { \"username\": \"gh_tech_user_login\", \"password\": os.getenv('GH_ACCESS_TOKEN'), \"registry_url\": \"https://maven.pkg.github.com/Netcracker/*\", }","title":"GitHub Packages"},{"location":"maven_auth/#google-cloud-gar-google-artifact-registry","text":"Official documentation on this process is here You need to use service account key as a credential. So the process is: Create new Service Account with minimum required roles/permissions to access your Artifact Registry (e.g. \"Artifact Registry Reader\" role) Create new Service Account Key - and download it (it's a .json file) base64 encode this file to get your authentication token (e.g. base64 -w 0 your_key.json > encoded_key.txt ) username should be _json_key_base64 params_gcp = { \"username\": \"_json_key_base64\", \"password\": os.getenv('GAR_ACCESS_TOKEN'), \"registry_url\": \"https://LOCATION-maven.pkg.dev/PROJECT/REPOSITORY\", } maven_searcher = MavenArtifactSearcher(params_gcp.get(\"registry_url\")).with_gcp_artifact_registry({\"service_account_key\": params_gcp.get(\"password\")}, PROJECT, REGION, REPOSITORY)","title":"Google Cloud GAR (Google Artifact Registry)"},{"location":"maven_auth/#aws-code-artifact","text":"Official AWS documentation is here You access Code Artifact repositories using special temporary token, but it's only valid for up to 12 hours. To use persistent credentials, this library provides utility helper AWSCodeArtifactHelper that can generate token for you using Access + Secret keys and your domain + region. You need to create an IAM User with required policies/permissions ( instructions here ) Get Access Key and Secret Key to this user, you'll need them to generate your temporary authorization token to Code Artifact params_aws = { \"username\": \"aws\", \"password\": AWSCodeArtifactHelper.get_authorization_token( os.getenv('AWS_ACCESS_KEY'), os.getenv('AWS_SECRET_KEY'), \"test-maven-domain\", \"us-east-1\" ), \"registry_url\": \"https://test-maven-domain-123.d.codeartifact.us-east-1.amazonaws.com/maven/test-maven-repo/\", } maven_searcher = MavenArtifactSearcher(params_aws.get(\"registry_url\")).with_aws_code_artifact(os.getenv('AWS_ACCESS_KEY'), os.getenv('AWS_SECRET_KEY'), DOMAIN, REGION, REPOSITORY)","title":"AWS Code Artifact"},{"location":"mkdocs/","text":"Qubership Pipelines Common Library Open-source python library of clients used by Qubership pipelines/modules. Library provides easy-to-use clients and wrappers for common DevOps services (e.g. Jenkins, MiniO, GitLab Pipelines) Sample implementation Sample implementation of CLI commands using this library is available at qubership-pipelines-cli-command-samples It includes reference python implementation along with the Development Guide Structure Library is presented as a set of clients with predefined operations Auto-generated reference (via mkdocs) is available on this repo's GitHub Pages Installation Add the following section to your dependencies to add Qubership library as a dependency in your project: [tool.poetry.dependencies] qubership-pipelines-common-library = \"*\" Or you can install it via pip : pip install qubership-pipelines-common-library Backported version There also exists backported to python3.9 version of this library You can install it via pip : pip install qubership-pipelines-common-library-py39","title":"Home"},{"location":"mkdocs/#qubership-pipelines-common-library","text":"Open-source python library of clients used by Qubership pipelines/modules. Library provides easy-to-use clients and wrappers for common DevOps services (e.g. Jenkins, MiniO, GitLab Pipelines)","title":"Qubership Pipelines Common Library"},{"location":"mkdocs/#sample-implementation","text":"Sample implementation of CLI commands using this library is available at qubership-pipelines-cli-command-samples It includes reference python implementation along with the Development Guide","title":"Sample implementation"},{"location":"mkdocs/#structure","text":"Library is presented as a set of clients with predefined operations Auto-generated reference (via mkdocs) is available on this repo's GitHub Pages","title":"Structure"},{"location":"mkdocs/#installation","text":"Add the following section to your dependencies to add Qubership library as a dependency in your project: [tool.poetry.dependencies] qubership-pipelines-common-library = \"*\" Or you can install it via pip : pip install qubership-pipelines-common-library","title":"Installation"},{"location":"mkdocs/#backported-version","text":"There also exists backported to python3.9 version of this library You can install it via pip : pip install qubership-pipelines-common-library-py39","title":"Backported version"},{"location":"mkdocs/clients/","text":"ArtifactoryClient ArtifactoryClient(params: dict ) params is a dictionary with following mandatory params: Parameters: url ( str ) \u2013 Artifactory host url username ( str ) \u2013 User used in auth request password ( str ) \u2013 Token used in auth request get_artifact_properties get_artifact_properties(path_to_artifact: str ) get_folder_files_list get_folder_files_list(path_to_folder: str ) get_artifact_content_by_url get_artifact_content_by_url(path_to_file: str ) ArtifactFinder ArtifactFinder(artifact_provider: ArtifactProvider , **kwargs) Allows searching for specific descriptor artifacts in different repositories without knowing full coordinates (e.g. knowing only artifact_id and version , but not its group_id ) Supports different repository providers: Artifactory, Nexus, AWS, GCP, Azure Provides different auth methods for Cloud Providers, implementing CloudCredentialsProvider interface Start by initializing this client with one of implementations: finder = ArtifactFinder(artifact_provider=ArtifactoryProvider(registry_url=\"https://our_url\", username=\"user\", password=\"password\")) Then find your artifacts using resource_urls = finder.find_artifact_urls(artifact_id='art_id', version='1.0.0', extension='json') Additionally, perform filtering of returned results (if you expect to find more than one artifact), and then download necessary artifacts with finder.download_artifact(one_of_the_returned_resource_urls, './my_artifact.json') For more complex providers (e.g. AWS Code Artifact), you need to use specific Credential Providers As an example: aws_creds = AwsCredentialsProvider().with_assume_role(...all the required params...).get_credentials() aws_code_artifact_provider = AwsCodeArtifactProvider(creds=creds, domain='our_domain', project='our_project') finder = ArtifactFinder(artifact_provider=aws_code_artifact_provider) GitClient GitClient(host: str , username: str , password: str , email: str = None) Parameters: host ( str ) \u2013 Git instance URL username ( str ) \u2013 User used in auth request password ( str ) \u2013 Token used in auth request email ( str , default: None ) \u2013 Email used when committing changes using client clone clone(repo_path: str , branch: str , temp_path: str , **kwargs) clone_repo_from_commit_hash clone_repo_from_commit_hash(repo_path: str , commit_hash: str , temp_path: str ) commit_and_push commit_and_push(commit_message: str ) commit commit(commit_message: str ) push push() pull pull(**kwargs) get_file_content_utf8 get_file_content_utf8(relative_path: str ) set_file_content_utf8 set_file_content_utf8(relative_path: str , content: str ) delete_by_path delete_by_path(relative_path: str ) GithubClient GithubClient(token: str = None, api_url: str = None, **kwargs) Bases: GithubClient This class is deprecated and will be removed in v3.0.0. Use class from v2 module instead. Arguments: token (str): Token used in auth request api_url (str): Optional Github Enterprise API URL, leave empty if using github.com **kwargs (Any): will be passed into Github API constructor trigger_workflow trigger_workflow(owner: str , repo_name: str , workflow_file_name: str , branch: str , pipeline_params: dict , timeout_seconds: float = 30.0, wait_seconds: float = 3.0, find_via_uuid: bool = False, uuid_param_name: str = DEFAULT_UUID_PARAM_NAME , uuid_artifact_name: str = DEFAULT_UUID_ARTIFACT_NAME , uuid_file_name: str = DEFAULT_UUID_FILE_NAME ) There's currently no reliable way to get ID of triggered workflow, without adding explicit ID as an input parameter to each workflow, dispatch is async and doesn't return anything This method supports two different ways to find and return started workflow: Unreliable - where we start looking for newly created runs of that workflow, filtering them as much as possible (might return wrong run in a concurrent scenario) Reliable: you need to add specific explicit ID param to the workflow you are triggering (e.g. 'workflow_run_uuid'), said workflow should have a step where it will save its input params, and then you run this method with 'find_via_uuid = True' get_workflow_run_status get_workflow_run_status(execution: ExecutionInfo ) wait_workflow_run_execution wait_workflow_run_execution(execution: ExecutionInfo , timeout_seconds: float = 60.0, break_status_list: list = None, wait_seconds: float = 10.0) cancel_workflow_run_execution cancel_workflow_run_execution(execution: ExecutionInfo , timeout: float = 1.0) download_workflow_run_artifacts download_workflow_run_artifacts(execution: ExecutionInfo , local_dir: str ) get_workflow_run_input_params get_workflow_run_input_params(execution: ExecutionInfo , artifact_name: str = DEFAULT_UUID_ARTIFACT_NAME , file_name: str = DEFAULT_UUID_FILE_NAME ) GitlabClient GitlabClient(host: str , username: str , password: str , email: str = None, **kwargs) Bases: GitlabClient This class is deprecated and will be removed in v3.0.0. Use class from v2 module instead. Arguments: host (str): Gitlab instance URL username (str): User used in auth request, might be empty string if no auth is required password (str): Token used in auth request email (str): Email used when committing changes using API **kwargs (Any): will be passed into Gitlab API constructor trigger_pipeline trigger_pipeline(project_id: str , ref: str , trigger_token: str = None, variables: dict = None, use_ci_job_token: bool = False) create_pipeline create_pipeline(project_id: str , ref: str , variables: dict ) get_file_content get_file_content(project_id: str , ref: str , file_path: str ) create_file create_file(project_id: str , file_path: str , content: str , ref: str , commit_message: str ) update_file update_file(project_id: str , file_path: str , content: str , ref: str , commit_message: str , create_if_not_exists: bool = False) delete_file delete_file(project_id: str , file_path: str , ref: str , commit_message: str ) get_latest_commit_id get_latest_commit_id(project_id: str , ref: str ) get_file_commit_info get_file_commit_info(project_id: str , ref: str , file_path: str ) Returns dict with 'commit_id' and 'last_commit_id' from Gitlab API cancel_pipeline_execution cancel_pipeline_execution(execution: ExecutionInfo , timeout: float = 1.0) get_pipeline_status get_pipeline_status(execution: ExecutionInfo ) wait_pipeline_execution wait_pipeline_execution(execution: ExecutionInfo , timeout_seconds: float = 180.0, break_status_list: list = None, wait_seconds: float = 1.0) get_repo_branch_path staticmethod get_repo_branch_path(url: str , branch: str = 'main') Extracts 'repo', 'branch' and 'path' parts from possible Gitlab URLs. Needs to know branch beforehand is_gitlab_project_exist staticmethod is_gitlab_project_exist(gitlab_url, gitlab_project, gitlab_token) search_group_id staticmethod search_group_id(gitlab_url, gitlab_project, gitlab_token) create_internal_gitlab_project staticmethod create_internal_gitlab_project(gitlab_url, gitlab_token, group_id, repo_name, repo_branch, visibility='internal') make_first_commit_to_gitlab_project staticmethod make_first_commit_to_gitlab_project(gitlab_url, gitlab_token, project_id, repo_branch) JenkinsClient JenkinsClient(host: str , user: str , password: str ) Bases: JenkinsClient This class is deprecated and will be removed in v3.0.0. Use class from v2 module instead. Arguments: host (str): Jenkins host URL user (str): User used in auth request password (str): Token used in auth request run_pipeline run_pipeline(job_name: str , job_params: dict , timeout_seconds: float = 180.0, wait_seconds: float = 1.0) get_pipeline_execution_status get_pipeline_execution_status(execution: ExecutionInfo , timeout_seconds: float = 30.0, wait_seconds: float = 1.0) wait_pipeline_execution wait_pipeline_execution(execution: ExecutionInfo , timeout_seconds: float = 180.0, wait_seconds: float = 1.0) cancel_pipeline_execution cancel_pipeline_execution(execution: ExecutionInfo , timeout_seconds: float = 30.0, wait_seconds: float = 1.0) get_pipeline_execution_artifacts get_pipeline_execution_artifacts(execution: ExecutionInfo , timeout_seconds: float = 30.0, wait_seconds: float = 1.0) Returns list of artifact relative paths save_pipeline_execution_artifact_to_file save_pipeline_execution_artifact_to_file(execution: ExecutionInfo , artifact_path: str , file_path: str ) JiraClient JiraClient(host: str , user: str , password: str , auth_type: str = BASIC ) KubeClient KubeClient(endpoint: str = None, token: str = None, kubeconfig_path: str = None) Needs either of endpoint and token or kubeconfig_path Parameters: endpoint ( str , default: None ) \u2013 Kubernetes API server URL token ( str , default: None ) \u2013 Token used for cluster access kubeconfig_path ( str , default: None ) \u2013 Path to local .kubeconfig file list_namespaces list_namespaces() namespace_exists namespace_exists(namespace: str ) deployments_exist deployments_exist(namespace: str ) is_namespace_scaled_to_zero is_namespace_scaled_to_zero(namespace: str ) list_not_ready_resources list_not_ready_resources(namespace) create_namespace create_namespace(namespace: str ) delete_namespaces delete_namespaces(namespaces: list [ str ], ignore_not_found: bool = False) list_config_map_names list_config_map_names(namespace: str ) read_config_map read_config_map(namespace: str , config_map_name: str ) create_config_map create_config_map(namespace: str , config_map_name: str , config_map_data: dict ) patch_config_map patch_config_map(namespace: str , config_map_name: str , config_map_data: dict ) Patching allows adding/removing only specified keys in config map. Removes key-value pair when value is None replace_config_map replace_config_map(namespace: str , config_map_name: str , config_map_data: dict ) Replaces all data inside existing config map with value of 'config_map_data' argument create_or_replace_config_map create_or_replace_config_map(namespace: str , config_map_name: str , config_map_data: dict ) Creates map if it doesn't exist, replaces it otherwise delete_config_map delete_config_map(namespace: str , config_map_name: str ) scale_namespace scale_namespace(namespace: str , scale_mode: ScaleMode , use_config_map: bool = True, replicas: int = 0) scale_namespace_down scale_namespace_down(namespace: str ) scale_namespace_up scale_namespace_up(namespace: str , use_config_map: bool , replicas: int = 0) MinioClient MinioClient(endpoint: str , access_key: str , secret_key: str , secure: bool = True, cert_check: bool = True) Parameters: endpoint ( str ) \u2013 MiniO host URL access_key ( str ) \u2013 Access key used in auth request secret_key ( str ) \u2013 Secret key used in auth request secure ( bool , default: True ) \u2013 Which protocol to use (in case it's not present in endpoint ) cert_check ( bool , default: True ) \u2013 Whether to verify certificate list_objects list_objects(bucket_name: str , path: str = None) No leading slash in path - newer versions of MiniO don't support it, Trailing slash in path must be present e.g. don't do this: path=\"/folder1/folder2\" do this: path=\"folder/folder2/\" get_folder_names get_folder_names(bucket_name: str , path: str = None) get_file_names get_file_names(bucket_name: str , path: str = None) get_last_modified_file get_last_modified_file(bucket_name: str , path: str = None) get_last_modified_text_file_content get_last_modified_text_file_content(bucket_name: str , path: str = None) get_file get_file(bucket_name: str , file_path: str , local_path: str ) put_file put_file(bucket_name: str , path: str , local_path: str ) get_text_file_content get_text_file_content(bucket_name: str , file_path: str ) WebexClient WebexClient(bot_token: str , proxies: dict = None) proxies dict for different protocols is passed to requests session. e.g. proxies = { 'https' : 'https://user:password@ip:port' } Parameters: bot_token ( str ) \u2013 bot's auth token proxies ( dict , default: None ) \u2013 dict with proxy connections for different protocols send_message send_message(room_id: str , msg: str = None, attachment_path: str = None, parent_id: str = None, to_person_id: str = None, to_person_email: str = None, markdown: str = None, **request_parameters) Post a message to a room. Parameters: room_id ( str ) \u2013 The room ID. to_person_id ( str , default: None ) \u2013 The ID of the recipient when sending a private 1:1 message. to_person_email ( str , default: None ) \u2013 The email address of the recipient when sending a private 1:1 message. msg ( str , default: None ) \u2013 The message, in plain text. If markdown is specified this parameter may be optionally used to provide alternate text for UI clients that do not support rich text. markdown ( str , default: None ) \u2013 The message, in Markdown format. attachment_path ( str , default: None ) \u2013 Path to file that will be attached to a message parent_id ( str , default: None ) \u2013 The parent message to reply to. This will start or reply to a thread. **request_parameters \u2013 Additional request parameters (provides support for parameters that may be added in the future). Returns \u2013 dict: The API response containing details of the created message.","title":"Clients"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.artifactory_client.ArtifactoryClient","text":"ArtifactoryClient(params: dict ) params is a dictionary with following mandatory params: Parameters: url ( str ) \u2013 Artifactory host url username ( str ) \u2013 User used in auth request password ( str ) \u2013 Token used in auth request","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;ArtifactoryClient"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.artifactory_client.ArtifactoryClient.get_artifact_properties","text":"get_artifact_properties(path_to_artifact: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_artifact_properties"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.artifactory_client.ArtifactoryClient.get_folder_files_list","text":"get_folder_files_list(path_to_folder: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_folder_files_list"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.artifactory_client.ArtifactoryClient.get_artifact_content_by_url","text":"get_artifact_content_by_url(path_to_file: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_artifact_content_by_url"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.artifacts_finder.artifact_finder.ArtifactFinder","text":"ArtifactFinder(artifact_provider: ArtifactProvider , **kwargs) Allows searching for specific descriptor artifacts in different repositories without knowing full coordinates (e.g. knowing only artifact_id and version , but not its group_id ) Supports different repository providers: Artifactory, Nexus, AWS, GCP, Azure Provides different auth methods for Cloud Providers, implementing CloudCredentialsProvider interface Start by initializing this client with one of implementations: finder = ArtifactFinder(artifact_provider=ArtifactoryProvider(registry_url=\"https://our_url\", username=\"user\", password=\"password\")) Then find your artifacts using resource_urls = finder.find_artifact_urls(artifact_id='art_id', version='1.0.0', extension='json') Additionally, perform filtering of returned results (if you expect to find more than one artifact), and then download necessary artifacts with finder.download_artifact(one_of_the_returned_resource_urls, './my_artifact.json') For more complex providers (e.g. AWS Code Artifact), you need to use specific Credential Providers As an example: aws_creds = AwsCredentialsProvider().with_assume_role(...all the required params...).get_credentials() aws_code_artifact_provider = AwsCodeArtifactProvider(creds=creds, domain='our_domain', project='our_project') finder = ArtifactFinder(artifact_provider=aws_code_artifact_provider)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;ArtifactFinder"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.git_client.GitClient","text":"GitClient(host: str , username: str , password: str , email: str = None) Parameters: host ( str ) \u2013 Git instance URL username ( str ) \u2013 User used in auth request password ( str ) \u2013 Token used in auth request email ( str , default: None ) \u2013 Email used when committing changes using client","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;GitClient"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.git_client.GitClient.clone","text":"clone(repo_path: str , branch: str , temp_path: str , **kwargs)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;clone"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.git_client.GitClient.clone_repo_from_commit_hash","text":"clone_repo_from_commit_hash(repo_path: str , commit_hash: str , temp_path: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;clone_repo_from_commit_hash"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.git_client.GitClient.commit_and_push","text":"commit_and_push(commit_message: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;commit_and_push"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.git_client.GitClient.commit","text":"commit(commit_message: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;commit"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.git_client.GitClient.push","text":"push()","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;push"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.git_client.GitClient.pull","text":"pull(**kwargs)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;pull"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.git_client.GitClient.get_file_content_utf8","text":"get_file_content_utf8(relative_path: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_file_content_utf8"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.git_client.GitClient.set_file_content_utf8","text":"set_file_content_utf8(relative_path: str , content: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;set_file_content_utf8"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.git_client.GitClient.delete_by_path","text":"delete_by_path(relative_path: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;delete_by_path"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.github.github_client.GithubClient","text":"GithubClient(token: str = None, api_url: str = None, **kwargs) Bases: GithubClient This class is deprecated and will be removed in v3.0.0. Use class from v2 module instead. Arguments: token (str): Token used in auth request api_url (str): Optional Github Enterprise API URL, leave empty if using github.com **kwargs (Any): will be passed into Github API constructor","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;GithubClient"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.github.github_client.GithubClient.trigger_workflow","text":"trigger_workflow(owner: str , repo_name: str , workflow_file_name: str , branch: str , pipeline_params: dict , timeout_seconds: float = 30.0, wait_seconds: float = 3.0, find_via_uuid: bool = False, uuid_param_name: str = DEFAULT_UUID_PARAM_NAME , uuid_artifact_name: str = DEFAULT_UUID_ARTIFACT_NAME , uuid_file_name: str = DEFAULT_UUID_FILE_NAME ) There's currently no reliable way to get ID of triggered workflow, without adding explicit ID as an input parameter to each workflow, dispatch is async and doesn't return anything This method supports two different ways to find and return started workflow: Unreliable - where we start looking for newly created runs of that workflow, filtering them as much as possible (might return wrong run in a concurrent scenario) Reliable: you need to add specific explicit ID param to the workflow you are triggering (e.g. 'workflow_run_uuid'), said workflow should have a step where it will save its input params, and then you run this method with 'find_via_uuid = True'","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;trigger_workflow"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.github.github_client.GithubClient.get_workflow_run_status","text":"get_workflow_run_status(execution: ExecutionInfo )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_workflow_run_status"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.github.github_client.GithubClient.wait_workflow_run_execution","text":"wait_workflow_run_execution(execution: ExecutionInfo , timeout_seconds: float = 60.0, break_status_list: list = None, wait_seconds: float = 10.0)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;wait_workflow_run_execution"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.github.github_client.GithubClient.cancel_workflow_run_execution","text":"cancel_workflow_run_execution(execution: ExecutionInfo , timeout: float = 1.0)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;cancel_workflow_run_execution"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.github.github_client.GithubClient.download_workflow_run_artifacts","text":"download_workflow_run_artifacts(execution: ExecutionInfo , local_dir: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;download_workflow_run_artifacts"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.github.github_client.GithubClient.get_workflow_run_input_params","text":"get_workflow_run_input_params(execution: ExecutionInfo , artifact_name: str = DEFAULT_UUID_ARTIFACT_NAME , file_name: str = DEFAULT_UUID_FILE_NAME )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_workflow_run_input_params"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient","text":"GitlabClient(host: str , username: str , password: str , email: str = None, **kwargs) Bases: GitlabClient This class is deprecated and will be removed in v3.0.0. Use class from v2 module instead. Arguments: host (str): Gitlab instance URL username (str): User used in auth request, might be empty string if no auth is required password (str): Token used in auth request email (str): Email used when committing changes using API **kwargs (Any): will be passed into Gitlab API constructor","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;GitlabClient"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.trigger_pipeline","text":"trigger_pipeline(project_id: str , ref: str , trigger_token: str = None, variables: dict = None, use_ci_job_token: bool = False)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;trigger_pipeline"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.create_pipeline","text":"create_pipeline(project_id: str , ref: str , variables: dict )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;create_pipeline"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.get_file_content","text":"get_file_content(project_id: str , ref: str , file_path: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_file_content"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.create_file","text":"create_file(project_id: str , file_path: str , content: str , ref: str , commit_message: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;create_file"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.update_file","text":"update_file(project_id: str , file_path: str , content: str , ref: str , commit_message: str , create_if_not_exists: bool = False)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;update_file"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.delete_file","text":"delete_file(project_id: str , file_path: str , ref: str , commit_message: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;delete_file"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.get_latest_commit_id","text":"get_latest_commit_id(project_id: str , ref: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_latest_commit_id"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.get_file_commit_info","text":"get_file_commit_info(project_id: str , ref: str , file_path: str ) Returns dict with 'commit_id' and 'last_commit_id' from Gitlab API","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_file_commit_info"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.cancel_pipeline_execution","text":"cancel_pipeline_execution(execution: ExecutionInfo , timeout: float = 1.0)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;cancel_pipeline_execution"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.get_pipeline_status","text":"get_pipeline_status(execution: ExecutionInfo )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_pipeline_status"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.wait_pipeline_execution","text":"wait_pipeline_execution(execution: ExecutionInfo , timeout_seconds: float = 180.0, break_status_list: list = None, wait_seconds: float = 1.0)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;wait_pipeline_execution"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.get_repo_branch_path","text":"get_repo_branch_path(url: str , branch: str = 'main') Extracts 'repo', 'branch' and 'path' parts from possible Gitlab URLs. Needs to know branch beforehand","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_repo_branch_path"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.is_gitlab_project_exist","text":"is_gitlab_project_exist(gitlab_url, gitlab_project, gitlab_token)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;is_gitlab_project_exist"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.search_group_id","text":"search_group_id(gitlab_url, gitlab_project, gitlab_token)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;search_group_id"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.create_internal_gitlab_project","text":"create_internal_gitlab_project(gitlab_url, gitlab_token, group_id, repo_name, repo_branch, visibility='internal')","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;create_internal_gitlab_project"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.gitlab.gitlab_client.GitlabClient.make_first_commit_to_gitlab_project","text":"make_first_commit_to_gitlab_project(gitlab_url, gitlab_token, project_id, repo_branch)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;make_first_commit_to_gitlab_project"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.jenkins.jenkins_client.JenkinsClient","text":"JenkinsClient(host: str , user: str , password: str ) Bases: JenkinsClient This class is deprecated and will be removed in v3.0.0. Use class from v2 module instead. Arguments: host (str): Jenkins host URL user (str): User used in auth request password (str): Token used in auth request","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;JenkinsClient"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.jenkins.jenkins_client.JenkinsClient.run_pipeline","text":"run_pipeline(job_name: str , job_params: dict , timeout_seconds: float = 180.0, wait_seconds: float = 1.0)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;run_pipeline"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.jenkins.jenkins_client.JenkinsClient.get_pipeline_execution_status","text":"get_pipeline_execution_status(execution: ExecutionInfo , timeout_seconds: float = 30.0, wait_seconds: float = 1.0)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_pipeline_execution_status"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.jenkins.jenkins_client.JenkinsClient.wait_pipeline_execution","text":"wait_pipeline_execution(execution: ExecutionInfo , timeout_seconds: float = 180.0, wait_seconds: float = 1.0)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;wait_pipeline_execution"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.jenkins.jenkins_client.JenkinsClient.cancel_pipeline_execution","text":"cancel_pipeline_execution(execution: ExecutionInfo , timeout_seconds: float = 30.0, wait_seconds: float = 1.0)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;cancel_pipeline_execution"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.jenkins.jenkins_client.JenkinsClient.get_pipeline_execution_artifacts","text":"get_pipeline_execution_artifacts(execution: ExecutionInfo , timeout_seconds: float = 30.0, wait_seconds: float = 1.0) Returns list of artifact relative paths","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_pipeline_execution_artifacts"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.jenkins.jenkins_client.JenkinsClient.save_pipeline_execution_artifact_to_file","text":"save_pipeline_execution_artifact_to_file(execution: ExecutionInfo , artifact_path: str , file_path: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;save_pipeline_execution_artifact_to_file"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v2.jira.jira_client.JiraClient","text":"JiraClient(host: str , user: str , password: str , auth_type: str = BASIC )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;JiraClient"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient","text":"KubeClient(endpoint: str = None, token: str = None, kubeconfig_path: str = None) Needs either of endpoint and token or kubeconfig_path Parameters: endpoint ( str , default: None ) \u2013 Kubernetes API server URL token ( str , default: None ) \u2013 Token used for cluster access kubeconfig_path ( str , default: None ) \u2013 Path to local .kubeconfig file","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;KubeClient"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.list_namespaces","text":"list_namespaces()","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;list_namespaces"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.namespace_exists","text":"namespace_exists(namespace: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;namespace_exists"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.deployments_exist","text":"deployments_exist(namespace: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;deployments_exist"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.is_namespace_scaled_to_zero","text":"is_namespace_scaled_to_zero(namespace: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;is_namespace_scaled_to_zero"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.list_not_ready_resources","text":"list_not_ready_resources(namespace)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;list_not_ready_resources"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.create_namespace","text":"create_namespace(namespace: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;create_namespace"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.delete_namespaces","text":"delete_namespaces(namespaces: list [ str ], ignore_not_found: bool = False)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;delete_namespaces"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.list_config_map_names","text":"list_config_map_names(namespace: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;list_config_map_names"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.read_config_map","text":"read_config_map(namespace: str , config_map_name: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;read_config_map"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.create_config_map","text":"create_config_map(namespace: str , config_map_name: str , config_map_data: dict )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;create_config_map"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.patch_config_map","text":"patch_config_map(namespace: str , config_map_name: str , config_map_data: dict ) Patching allows adding/removing only specified keys in config map. Removes key-value pair when value is None","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;patch_config_map"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.replace_config_map","text":"replace_config_map(namespace: str , config_map_name: str , config_map_data: dict ) Replaces all data inside existing config map with value of 'config_map_data' argument","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;replace_config_map"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.create_or_replace_config_map","text":"create_or_replace_config_map(namespace: str , config_map_name: str , config_map_data: dict ) Creates map if it doesn't exist, replaces it otherwise","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;create_or_replace_config_map"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.delete_config_map","text":"delete_config_map(namespace: str , config_map_name: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;delete_config_map"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.scale_namespace","text":"scale_namespace(namespace: str , scale_mode: ScaleMode , use_config_map: bool = True, replicas: int = 0)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;scale_namespace"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.scale_namespace_down","text":"scale_namespace_down(namespace: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;scale_namespace_down"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.kube_client.KubeClient.scale_namespace_up","text":"scale_namespace_up(namespace: str , use_config_map: bool , replicas: int = 0)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;scale_namespace_up"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.minio_client.MinioClient","text":"MinioClient(endpoint: str , access_key: str , secret_key: str , secure: bool = True, cert_check: bool = True) Parameters: endpoint ( str ) \u2013 MiniO host URL access_key ( str ) \u2013 Access key used in auth request secret_key ( str ) \u2013 Secret key used in auth request secure ( bool , default: True ) \u2013 Which protocol to use (in case it's not present in endpoint ) cert_check ( bool , default: True ) \u2013 Whether to verify certificate","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;MinioClient"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.minio_client.MinioClient.list_objects","text":"list_objects(bucket_name: str , path: str = None) No leading slash in path - newer versions of MiniO don't support it, Trailing slash in path must be present e.g. don't do this: path=\"/folder1/folder2\" do this: path=\"folder/folder2/\"","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;list_objects"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.minio_client.MinioClient.get_folder_names","text":"get_folder_names(bucket_name: str , path: str = None)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_folder_names"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.minio_client.MinioClient.get_file_names","text":"get_file_names(bucket_name: str , path: str = None)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_file_names"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.minio_client.MinioClient.get_last_modified_file","text":"get_last_modified_file(bucket_name: str , path: str = None)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_last_modified_file"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.minio_client.MinioClient.get_last_modified_text_file_content","text":"get_last_modified_text_file_content(bucket_name: str , path: str = None)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_last_modified_text_file_content"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.minio_client.MinioClient.get_file","text":"get_file(bucket_name: str , file_path: str , local_path: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_file"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.minio_client.MinioClient.put_file","text":"put_file(bucket_name: str , path: str , local_path: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;put_file"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.minio_client.MinioClient.get_text_file_content","text":"get_text_file_content(bucket_name: str , file_path: str )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_text_file_content"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.webex_client.WebexClient","text":"WebexClient(bot_token: str , proxies: dict = None) proxies dict for different protocols is passed to requests session. e.g. proxies = { 'https' : 'https://user:password@ip:port' } Parameters: bot_token ( str ) \u2013 bot's auth token proxies ( dict , default: None ) \u2013 dict with proxy connections for different protocols","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;WebexClient"},{"location":"mkdocs/clients/#qubership_pipelines_common_library.v1.webex_client.WebexClient.send_message","text":"send_message(room_id: str , msg: str = None, attachment_path: str = None, parent_id: str = None, to_person_id: str = None, to_person_email: str = None, markdown: str = None, **request_parameters) Post a message to a room. Parameters: room_id ( str ) \u2013 The room ID. to_person_id ( str , default: None ) \u2013 The ID of the recipient when sending a private 1:1 message. to_person_email ( str , default: None ) \u2013 The email address of the recipient when sending a private 1:1 message. msg ( str , default: None ) \u2013 The message, in plain text. If markdown is specified this parameter may be optionally used to provide alternate text for UI clients that do not support rich text. markdown ( str , default: None ) \u2013 The message, in Markdown format. attachment_path ( str , default: None ) \u2013 Path to file that will be attached to a message parent_id ( str , default: None ) \u2013 The parent message to reply to. This will start or reply to a thread. **request_parameters \u2013 Additional request parameters (provides support for parameters that may be added in the future). Returns \u2013 dict: The API response containing details of the created message.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;send_message"},{"location":"mkdocs/commands/","text":"GithubRunPipeline GithubRunPipeline(*args, pipeline_data_importer: PipelineDataImporter = None, **kwargs) Bases: ExecutionCommand Executes a GitHub Actions workflow pipeline and optionally imports artifacts. This command triggers a GitHub workflow run, monitors its execution, and provides options for importing workflow artifacts and custom data processing through extensible importers. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"pipeline_owner\": \"Netcracker\", # REQUIRED: Repository owner/organization \"pipeline_repo_name\": \"qubership-test-pipelines\", # REQUIRED: Repository name \"pipeline_workflow_file_name\": \"test.yaml\", # REQUIRED: Workflow filename (e.g., main.yaml, ci-cd.yml) \"pipeline_branch\": \"main\", # OPTIONAL: Branch to run workflow from (default: repo's default branch) \"pipeline_params\": { # OPTIONAL: Input parameters to pass to the workflow \"KEY1\": \"VALUE1\", \"KEY2\": \"VALUE2\" }, \"import_artifacts\": false, # OPTIONAL: Whether to import workflow artifacts (default: false) \"use_existing_pipeline\": 123456789, # OPTIONAL: Use existing workflow run ID instead of starting new one (debug feature) \"timeout_seconds\": 1800, # OPTIONAL: Maximum wait time for workflow completion in seconds (default: 1800, 0 for async execution) \"wait_seconds\": 1, # OPTIONAL: Wait interval between status checks in seconds (default: 1) \"retry_timeout_seconds\": 180, # OPTIONAL: Timeout for GitHub client initialization and workflow start retries in seconds (default: 180) \"retry_wait_seconds\": 1, # OPTIONAL: Wait interval between retries in seconds (default: 1) \"success_statuses\": \"SUCCESS,UNSTABLE\" # OPTIONAL: Comma-separated list of acceptable completion statuses (default: SUCCESS) } Systems Configuration (expected in \"systems.github\" block): { \"url\": \"https://github.com\", # OPTIONAL: GitHub UI URL for self-hosted instances (default: https://github.com) \"api_url\": \"https://api.github.com\", # OPTIONAL: GitHub API URL for self-hosted instances (default: https://api.github.com) \"password\": \"<github_token>\" # REQUIRED: GitHub access token with workflow permissions } Output Parameters params.build.url: URL to view the workflow run in GitHub params.build.id: ID of the executed workflow run params.build.status: Final status of the workflow execution params.build.date: Workflow start time in ISO format params.build.duration: Total execution duration in human-readable format params.build.name: Name of the workflow run Extension Points Custom pipeline data importers can be implemented by extending PipelineDataImporter interface PipelineDataImporter is passed into constructor of command via \"pipeline_data_importer\" arg Notes Setting timeout_seconds to 0 enables asynchronous execution (workflow starts but command doesn't wait for completion) For self-hosted GitHub Enterprise, configure both \"systems.github.url\" and \"systems.github.api_url\" Custom data importers receive the command context and can implement advanced processing logic GitlabRunPipeline GitlabRunPipeline(*args, pipeline_data_importer: PipelineDataImporter = None, **kwargs) Bases: ExecutionCommand Runs GitLab Pipeline via Trigger or Create API and optionally imports artifacts. This command runs GitLab Pipeline, monitors its execution, and provides options for importing resulting artifacts and custom data processing through extensible importers. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"pipeline_path\": \"path/to/gitlab_project\", # REQUIRED: Full pipeline path (e.g. \"group/subgroup/repo\") \"pipeline_branch\": \"main\", # OPTIONAL: Branch to run pipeline from (default: repo's default branch) \"trigger_type\": \"CREATE_PIPELINE\", # OPTIONAL: Which API will be used to trigger the pipeline (CREATE_PIPELINE or TRIGGER_PIPELINE) \"pipeline_params\": { # OPTIONAL: Input parameters to pass to the pipeline \"KEY1\": \"VALUE1\", \"KEY2\": \"VALUE2\" }, \"import_artifacts\": false, # OPTIONAL: Whether to import pipeline artifacts (default: false) \"use_existing_pipeline\": 123456789, # OPTIONAL: Use existing pipeline ID (or use 'latest' here) instead of starting new one (debug feature) \"timeout_seconds\": 1800, # OPTIONAL: Maximum wait time for pipeline completion in seconds (default: 1800, 0 for async execution) \"wait_seconds\": 1, # OPTIONAL: Wait interval between status checks in seconds (default: 1) \"retry_timeout_seconds\": 180, # OPTIONAL: Timeout for GitLab client initialization and pipeline start retries in seconds (default: 180) \"retry_wait_seconds\": 1, # OPTIONAL: Wait interval between retries in seconds (default: 1) \"success_statuses\": \"SUCCESS,UNSTABLE\" # OPTIONAL: Comma-separated list of acceptable completion statuses (default: SUCCESS) } Systems Configuration (expected in \"systems.gitlab\" block): { \"url\": \"https://github.com\", # OPTIONAL: GitLab URL for self-hosted instances (default: https://gitlab.com) \"password\": \"<gitlab_token>\" # REQUIRED: GitLab access token with CI/CD permissions \"trigger_token\": \"<gitlab_trigger_token>\" # OPTIONAL: Special token issued for triggering pipeline. If not provided - will try to use CI_JOB_TOKEN } Output Parameters params.build.url: URL to view the pipeline run in GitLab params.build.id: ID of the executed pipeline params.build.status: Final status of the pipeline execution params.build.date: Workflow start time in ISO format params.build.duration: Total execution duration in human-readable format params.build.name: Name of the pipeline execution Extension Points Custom pipeline data importers can be implemented by extending PipelineDataImporter interface PipelineDataImporter is passed into constructor of command via \"pipeline_data_importer\" arg Notes Setting timeout_seconds to 0 enables asynchronous execution (workflow starts but command doesn't wait for completion) For self-hosted GitLab instances, configure \"systems.github.url\" Custom data importers receive the command context and can implement advanced processing logic JenkinsRunPipeline JenkinsRunPipeline(*args, pipeline_data_importer: PipelineDataImporter = None, **kwargs) Bases: ExecutionCommand Runs Jenkins Pipeline and optionally imports artifacts. This command runs Jenkins Pipeline, monitors its execution, and provides options for importing resulting artifacts and custom data processing through extensible importers. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"pipeline_path\": \"TENANT-NAME/path/to/job\", # REQUIRED: Full pipeline path (e.g. \"TENANT/folder/job\") \"pipeline_params\": { # OPTIONAL: Input parameters to pass to the pipeline \"KEY1\": \"VALUE1\", # Side-note: if you want to run your parametrized job with default parameters, \"KEY2\": \"VALUE2\" # you still need to pass some fake params (they will be ignored by Jenkins), e.g. \"__fake_key\":\"fake_value\", }, # Otherwise, if this dict is empty - endpoint for non-parametrized jobs will be triggered \"import_artifacts\": true, # OPTIONAL: Whether to import pipeline artifacts (default: true) \"use_existing_pipeline\": 123456789, # OPTIONAL: Use existing pipeline ID instead of starting new one (debug feature) \"timeout_seconds\": 1800, # OPTIONAL: Maximum wait time for pipeline completion in seconds (default: 1800, 0 for async execution) \"wait_seconds\": 1, # OPTIONAL: Wait interval between status checks in seconds (default: 1) \"retry_timeout_seconds\": 180, # OPTIONAL: Timeout for GitLab client initialization and pipeline start retries in seconds (default: 180) \"retry_wait_seconds\": 1, # OPTIONAL: Wait interval between retries in seconds (default: 1) \"success_statuses\": \"SUCCESS,UNSTABLE\" # OPTIONAL: Comma-separated list of acceptable completion statuses (default: SUCCESS) } Systems Configuration (expected in \"systems.jenkins\" block): { \"url\": \"https://github.com\", # REQUIRED: Jenkins instance URL \"username\": \"<jenkins_user>\" # REQUIRED: Jenkins user \"password\": \"<jenkins_token>\" # REQUIRED: Jenkins password or token with job-triggering permissions } Output Parameters params.build.url: URL to view the pipeline run in GitLab params.build.id: ID of the executed pipeline params.build.status: Final status of the pipeline execution params.build.date: Workflow start time in ISO format params.build.duration: Total execution duration in human-readable format params.build.name: Name of the pipeline execution Extension Points Custom pipeline data importers can be implemented by extending PipelineDataImporter interface PipelineDataImporter is passed into constructor of command via \"pipeline_data_importer\" arg Notes Setting timeout_seconds to 0 enables asynchronous execution (workflow starts but command doesn't wait for completion, and won't fetch build id) JiraCreateTicket JiraCreateTicket(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Bases: ExecutionCommand Creates new issue/ticket in JIRA project. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"ticket\": { \"fields: { # REQUIRED: Dict structure that will be used as ticket-creation-body, without transformations \"project\": {\"key\": \"<YOUR_PROJECT_KEY>\"}, # REQUIRED: Project Key \"issuetype\": {\"name\": \"Bug\"}, # REQUIRED: Issue type name \"priority\": {\"name\": \"High\"}, # OPTIONAL: Other ticket fields with different formats, depending on your Project configuration \"duedate\": \"2030-02-20\", # OPTIONAL: Text-value fields need no dict wrappers \"summary\": \"[SOME_LABEL] Ticket Subject\", \"description\": \"Ticket body\", \"components\": [{\"name\":\"COMPONENT NAME\"}], \"labels\": [\"Test_Label1\"], }, \"comment\": \"your comment body\", # OPTIONAL: Comment to add to created ticket \"field_names_filter\": \"summary,issuetype,creator,status\", # OPTIONAL: Comma-separated names of fields to extract from created ticket to output params }, \"retry_timeout_seconds\": 180, # OPTIONAL: Timeout for JIRA client operations in seconds (default: 180) \"retry_wait_seconds\": 1, # OPTIONAL: Wait interval between retries in seconds (default: 1) } Systems Configuration (expected in \"systems.jira\" block): { \"url\": \"https://your_cloud_jira.atlassian.net\", # REQUIRED: JIRA server URL \"username\": \"your_username_or_email\", # REQUIRED: JIRA user login or email \"password\": \"<your_token>\", # REQUIRED: JIRA user token \"auth_type\": \"basic\" # OPTIONAL: 'basic' or 'bearer' } Command name: \"jira-create-ticket\" JiraAddTicketComment JiraAddTicketComment(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Bases: ExecutionCommand Adds comment to JIRA ticket and retrieves latest comments. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"ticket\": { \"id\": \"BUG-567\", # REQUIRED: Ticket ID \"comment\": \"your comment body\", # REQUIRED: Comment body \"latest_comments_count\": 50, # OPTIONAL: Number of latest comments to fetch }, \"retry_timeout_seconds\": 180, # OPTIONAL: Timeout for JIRA client operations in seconds (default: 180) \"retry_wait_seconds\": 1, # OPTIONAL: Wait interval between retries in seconds (default: 1) } Systems Configuration (expected in \"systems.jira\" block): { \"url\": \"https://your_cloud_jira.atlassian.net\", # REQUIRED: JIRA server URL \"username\": \"your_username_or_email\", # REQUIRED: JIRA user login or email \"password\": \"<your_token>\", # REQUIRED: JIRA user token \"auth_type\": \"basic\" # OPTIONAL: 'basic' or 'bearer' } Command name: \"jira-add-ticket-comment\" JiraUpdateTicket JiraUpdateTicket(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Bases: ExecutionCommand Updates ticket fields and transitions status. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"ticket\": { \"fields: { # REQUIRED: Dict structure that will be used as ticket-update-body, without transformations \"status\": {\"name\": \"Done\"}, # OPTIONAL: Next status name \"transition\": {\"name\": \"From Review to Done\"}, # OPTIONAL: Transition name \"priority\": {\"name\": \"High\"}, # OPTIONAL: Other ticket fields with different formats, depending on your Project configuration \"duedate\": \"2030-02-20\", # OPTIONAL: Text-value fields need no dict wrappers \"description\": \"Ticket body\", \"labels\": [\"Test_Label1\"], }, \"id\": \"BUG-567\", # REQUIRED: Ticket ID \"comment\": \"your comment body\", # OPTIONAL: Comment to add to created ticket \"field_names_filter\": \"summary,issuetype,creator,status\", # OPTIONAL: Comma-separated names of fields to extract from created ticket to output params }, \"retry_timeout_seconds\": 180, # OPTIONAL: Timeout for JIRA client operations in seconds (default: 180) \"retry_wait_seconds\": 1, # OPTIONAL: Wait interval between retries in seconds (default: 1) } Systems Configuration (expected in \"systems.jira\" block): { \"url\": \"https://your_cloud_jira.atlassian.net\", # REQUIRED: JIRA server URL \"username\": \"your_username_or_email\", # REQUIRED: JIRA user login or email \"password\": \"<your_token>\", # REQUIRED: JIRA user token \"auth_type\": \"basic\" # OPTIONAL: 'basic' or 'bearer' } Command name: \"jira-update-ticket\" PodmanRunImage PodmanRunImage(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Bases: ExecutionCommand Executes a container using \"podman run\" command. This command supports running containers with configurable execution parameters, environment variable management, file mounting, and output extraction. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"image\": \"docker.io/library/hello-world:latest\", # REQUIRED: Container image to run \"command\": \"python -m pipelines_declarative_executor run --pipeline_dir=\"/WORK/EXEC_DIR\"\", # OPTIONAL: Command to execute in container \"execution_config\": { # ALL OF THESE ARE OPTIONAL \"working_dir\": \"/some/dir/inside/container\", # Working directory inside container \"timeout\": \"600\", # Maximum execution time in seconds \"operations_timeout\": \"15\", # Timeout for operations like file copying \"remove_container\": True, # Whether to remove container after execution \"save_stdout_to_logs\": True, # Save container stdout to execution logs \"save_stdout_to_files\": True, # Save container stdout to output files \"save_stdout_to_params\": False, # Save container stdout to output parameters \"expected_return_codes\": \"0,125\", # Comma-separated list of acceptable exit codes \"additional_run_flags\": \"--cgroups=disabled\", # Optional string of flags that will be added to \"podman run\" command }, \"before_script\": { \"mounts\": { # Filesystem mounts, \"host_path: container_path\" \"output_files\": \"/WORK\", \"prepared_data\": \"/CONFIGS\" }, \"env_vars\": { \"explicit\": { # Direct environment variable assignment \"PIPELINES_DECLARATIVE_EXECUTOR_ENCRYPT_OUTPUT_SECURE_PARAMS\": False }, \"env_files\": [ # Environment files on host to load and pass into container \"../CONFIGS/sample.env\" ], \"pass_via_file\": { # Sensitive vars passed via temp file \"SOMETHING_VERY_SECURE\": \"PASSWORD\" }, \"host_prefixes\": [ # Host environment variable prefixes to pass through. Can use \"*\" to pass everything from host. \"SOME_PREFIX_*\" ] } }, \"after_script\": { \"copy_files_to_host\": { # Copy files from container to host after execution, \"host_path: container_path\" \"output_files/report.json\": \"/WORK/EXEC_DIR/pipeline_state/pipeline_ui_view.json\", \"output_files/pipeline_state\": \"/WORK/EXEC_DIR/pipeline_state\", }, \"extract_params_from_files\": { # OPTIONAL: Extract parameters from container files. Supports JSON, YAML, and ENV files \"SOME_FILE_IN_CONTAINER\": \"SECTION_NAME_IN_PARAMS_WHERE_IT_WILL_BE_STORED\", } } } Output Parameters params.execution_time: Total execution time in seconds params.return_code: Container exit code params.stdout: Container stdout (if save_stdout_to_params enabled) params.stderr: Container stderr (if save_stdout_to_params enabled) params.extracted_output.*: Extracted parameters from files (if extract_params_from_files configured) Notes The command automatically handles container lifecycle including start, execution, and cleanup All host-paths (including mount paths) are resolved relative to context directory. SendEmail SendEmail(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Bases: ExecutionCommand This command sends email notification with optional attachments. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"email_subject\": \"Report for 01.01.2026\", # REQUIRED: E-mail subject \"email_body\": \"Following jobs were completed: ...\", # REQUIRED: E-mail message \"email_recipients\": \"user1@qubership.org,user2@qubership.org\", # REQUIRED: Comma-separated list of recipients \"email_body_type\": \"plain\", # OPTIONAL: Either \"plain\" or \"html \"attachments\": { # OPTIONAL: Dict with attachments \"unique_attachment_key\": { \"name\": \"HTML_report.html\", # REQUIRED: File name used for attachment \"content\": \"<html>...</html>\", # REQUIRED: Text content put inside attachment \"mime_type\": \"text/html\", }, \"another_attachment_key\": {...} } } Systems Configuration (expected in \"systems.email\" block): { \"server\": \"your.mail.server.org\", # REQUIRED: E-mail host server \"port\": \"3025\" # REQUIRED: E-mail port \"user\": \"your@email.bot\" # REQUIRED: E-mail user \"password\": \"<email_password>\" # OPTIONAL: E-mail password \"use_ssl\": \"False\" # OPTIONAL: SMTP connection will use SSL mode (default: False) \"use_tls\": \"False\" # OPTIONAL: SMTP connection will use TLS mode (default: False) \"verify\": \"False\" # OPTIONAL: SSL Certificate verification (default: False) \"timeout_seconds\": \"60\" # OPTIONAL: SMTP connection timeout in seconds (default: 60) } Command name: \"send-email\" SendWebexMessage SendWebexMessage(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Bases: ExecutionCommand This command sends Webex message with optional attachments. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"webex_message\": \"Hello, world!\", # REQUIRED: Text message (Markdown format is supported) \"parent_id\": \"1234321\", # OPTIONAL: The parent message to reply to \"attachments\": { # OPTIONAL: Dict with attachments \"unique_attachment_key\": { \"name\": \"HTML_report.html\", # REQUIRED: File name used for attachment \"content\": \"<html>...</html>\", # REQUIRED: Text content put inside attachment \"mime_type\": \"text/html\", }, \"another_attachment_key\": {...} } } Systems Configuration (expected in \"systems.webex\" block): { \"room_id\": \"...Y2lzY29zc...\", # REQUIRED: Webex unique room_id where message will be posted \"token\": \"your_bot_account_token\" # REQUIRED: Bot/Service account token that will be used to send message \"proxy\": \"https://127.0.0.1\" # OPTIONAL: Host to be used as a webex-proxy } Output Parameters params.message_id: Received message_id of sent message params.attachment_message_ids: dict of attachment_name -> message_id Command name: \"send-webex-message\"","title":"Commands"},{"location":"mkdocs/commands/#qubership_pipelines_common_library.v2.github.github_run_pipeline_command.GithubRunPipeline","text":"GithubRunPipeline(*args, pipeline_data_importer: PipelineDataImporter = None, **kwargs) Bases: ExecutionCommand Executes a GitHub Actions workflow pipeline and optionally imports artifacts. This command triggers a GitHub workflow run, monitors its execution, and provides options for importing workflow artifacts and custom data processing through extensible importers. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"pipeline_owner\": \"Netcracker\", # REQUIRED: Repository owner/organization \"pipeline_repo_name\": \"qubership-test-pipelines\", # REQUIRED: Repository name \"pipeline_workflow_file_name\": \"test.yaml\", # REQUIRED: Workflow filename (e.g., main.yaml, ci-cd.yml) \"pipeline_branch\": \"main\", # OPTIONAL: Branch to run workflow from (default: repo's default branch) \"pipeline_params\": { # OPTIONAL: Input parameters to pass to the workflow \"KEY1\": \"VALUE1\", \"KEY2\": \"VALUE2\" }, \"import_artifacts\": false, # OPTIONAL: Whether to import workflow artifacts (default: false) \"use_existing_pipeline\": 123456789, # OPTIONAL: Use existing workflow run ID instead of starting new one (debug feature) \"timeout_seconds\": 1800, # OPTIONAL: Maximum wait time for workflow completion in seconds (default: 1800, 0 for async execution) \"wait_seconds\": 1, # OPTIONAL: Wait interval between status checks in seconds (default: 1) \"retry_timeout_seconds\": 180, # OPTIONAL: Timeout for GitHub client initialization and workflow start retries in seconds (default: 180) \"retry_wait_seconds\": 1, # OPTIONAL: Wait interval between retries in seconds (default: 1) \"success_statuses\": \"SUCCESS,UNSTABLE\" # OPTIONAL: Comma-separated list of acceptable completion statuses (default: SUCCESS) } Systems Configuration (expected in \"systems.github\" block): { \"url\": \"https://github.com\", # OPTIONAL: GitHub UI URL for self-hosted instances (default: https://github.com) \"api_url\": \"https://api.github.com\", # OPTIONAL: GitHub API URL for self-hosted instances (default: https://api.github.com) \"password\": \"<github_token>\" # REQUIRED: GitHub access token with workflow permissions } Output Parameters params.build.url: URL to view the workflow run in GitHub params.build.id: ID of the executed workflow run params.build.status: Final status of the workflow execution params.build.date: Workflow start time in ISO format params.build.duration: Total execution duration in human-readable format params.build.name: Name of the workflow run Extension Points Custom pipeline data importers can be implemented by extending PipelineDataImporter interface PipelineDataImporter is passed into constructor of command via \"pipeline_data_importer\" arg Notes Setting timeout_seconds to 0 enables asynchronous execution (workflow starts but command doesn't wait for completion) For self-hosted GitHub Enterprise, configure both \"systems.github.url\" and \"systems.github.api_url\" Custom data importers receive the command context and can implement advanced processing logic","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;GithubRunPipeline"},{"location":"mkdocs/commands/#qubership_pipelines_common_library.v2.gitlab.gitlab_run_pipeline_command.GitlabRunPipeline","text":"GitlabRunPipeline(*args, pipeline_data_importer: PipelineDataImporter = None, **kwargs) Bases: ExecutionCommand Runs GitLab Pipeline via Trigger or Create API and optionally imports artifacts. This command runs GitLab Pipeline, monitors its execution, and provides options for importing resulting artifacts and custom data processing through extensible importers. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"pipeline_path\": \"path/to/gitlab_project\", # REQUIRED: Full pipeline path (e.g. \"group/subgroup/repo\") \"pipeline_branch\": \"main\", # OPTIONAL: Branch to run pipeline from (default: repo's default branch) \"trigger_type\": \"CREATE_PIPELINE\", # OPTIONAL: Which API will be used to trigger the pipeline (CREATE_PIPELINE or TRIGGER_PIPELINE) \"pipeline_params\": { # OPTIONAL: Input parameters to pass to the pipeline \"KEY1\": \"VALUE1\", \"KEY2\": \"VALUE2\" }, \"import_artifacts\": false, # OPTIONAL: Whether to import pipeline artifacts (default: false) \"use_existing_pipeline\": 123456789, # OPTIONAL: Use existing pipeline ID (or use 'latest' here) instead of starting new one (debug feature) \"timeout_seconds\": 1800, # OPTIONAL: Maximum wait time for pipeline completion in seconds (default: 1800, 0 for async execution) \"wait_seconds\": 1, # OPTIONAL: Wait interval between status checks in seconds (default: 1) \"retry_timeout_seconds\": 180, # OPTIONAL: Timeout for GitLab client initialization and pipeline start retries in seconds (default: 180) \"retry_wait_seconds\": 1, # OPTIONAL: Wait interval between retries in seconds (default: 1) \"success_statuses\": \"SUCCESS,UNSTABLE\" # OPTIONAL: Comma-separated list of acceptable completion statuses (default: SUCCESS) } Systems Configuration (expected in \"systems.gitlab\" block): { \"url\": \"https://github.com\", # OPTIONAL: GitLab URL for self-hosted instances (default: https://gitlab.com) \"password\": \"<gitlab_token>\" # REQUIRED: GitLab access token with CI/CD permissions \"trigger_token\": \"<gitlab_trigger_token>\" # OPTIONAL: Special token issued for triggering pipeline. If not provided - will try to use CI_JOB_TOKEN } Output Parameters params.build.url: URL to view the pipeline run in GitLab params.build.id: ID of the executed pipeline params.build.status: Final status of the pipeline execution params.build.date: Workflow start time in ISO format params.build.duration: Total execution duration in human-readable format params.build.name: Name of the pipeline execution Extension Points Custom pipeline data importers can be implemented by extending PipelineDataImporter interface PipelineDataImporter is passed into constructor of command via \"pipeline_data_importer\" arg Notes Setting timeout_seconds to 0 enables asynchronous execution (workflow starts but command doesn't wait for completion) For self-hosted GitLab instances, configure \"systems.github.url\" Custom data importers receive the command context and can implement advanced processing logic","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;GitlabRunPipeline"},{"location":"mkdocs/commands/#qubership_pipelines_common_library.v2.jenkins.jenkins_run_pipeline_command.JenkinsRunPipeline","text":"JenkinsRunPipeline(*args, pipeline_data_importer: PipelineDataImporter = None, **kwargs) Bases: ExecutionCommand Runs Jenkins Pipeline and optionally imports artifacts. This command runs Jenkins Pipeline, monitors its execution, and provides options for importing resulting artifacts and custom data processing through extensible importers. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"pipeline_path\": \"TENANT-NAME/path/to/job\", # REQUIRED: Full pipeline path (e.g. \"TENANT/folder/job\") \"pipeline_params\": { # OPTIONAL: Input parameters to pass to the pipeline \"KEY1\": \"VALUE1\", # Side-note: if you want to run your parametrized job with default parameters, \"KEY2\": \"VALUE2\" # you still need to pass some fake params (they will be ignored by Jenkins), e.g. \"__fake_key\":\"fake_value\", }, # Otherwise, if this dict is empty - endpoint for non-parametrized jobs will be triggered \"import_artifacts\": true, # OPTIONAL: Whether to import pipeline artifacts (default: true) \"use_existing_pipeline\": 123456789, # OPTIONAL: Use existing pipeline ID instead of starting new one (debug feature) \"timeout_seconds\": 1800, # OPTIONAL: Maximum wait time for pipeline completion in seconds (default: 1800, 0 for async execution) \"wait_seconds\": 1, # OPTIONAL: Wait interval between status checks in seconds (default: 1) \"retry_timeout_seconds\": 180, # OPTIONAL: Timeout for GitLab client initialization and pipeline start retries in seconds (default: 180) \"retry_wait_seconds\": 1, # OPTIONAL: Wait interval between retries in seconds (default: 1) \"success_statuses\": \"SUCCESS,UNSTABLE\" # OPTIONAL: Comma-separated list of acceptable completion statuses (default: SUCCESS) } Systems Configuration (expected in \"systems.jenkins\" block): { \"url\": \"https://github.com\", # REQUIRED: Jenkins instance URL \"username\": \"<jenkins_user>\" # REQUIRED: Jenkins user \"password\": \"<jenkins_token>\" # REQUIRED: Jenkins password or token with job-triggering permissions } Output Parameters params.build.url: URL to view the pipeline run in GitLab params.build.id: ID of the executed pipeline params.build.status: Final status of the pipeline execution params.build.date: Workflow start time in ISO format params.build.duration: Total execution duration in human-readable format params.build.name: Name of the pipeline execution Extension Points Custom pipeline data importers can be implemented by extending PipelineDataImporter interface PipelineDataImporter is passed into constructor of command via \"pipeline_data_importer\" arg Notes Setting timeout_seconds to 0 enables asynchronous execution (workflow starts but command doesn't wait for completion, and won't fetch build id)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;JenkinsRunPipeline"},{"location":"mkdocs/commands/#qubership_pipelines_common_library.v2.jira.jira_create_ticket_command.JiraCreateTicket","text":"JiraCreateTicket(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Bases: ExecutionCommand Creates new issue/ticket in JIRA project. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"ticket\": { \"fields: { # REQUIRED: Dict structure that will be used as ticket-creation-body, without transformations \"project\": {\"key\": \"<YOUR_PROJECT_KEY>\"}, # REQUIRED: Project Key \"issuetype\": {\"name\": \"Bug\"}, # REQUIRED: Issue type name \"priority\": {\"name\": \"High\"}, # OPTIONAL: Other ticket fields with different formats, depending on your Project configuration \"duedate\": \"2030-02-20\", # OPTIONAL: Text-value fields need no dict wrappers \"summary\": \"[SOME_LABEL] Ticket Subject\", \"description\": \"Ticket body\", \"components\": [{\"name\":\"COMPONENT NAME\"}], \"labels\": [\"Test_Label1\"], }, \"comment\": \"your comment body\", # OPTIONAL: Comment to add to created ticket \"field_names_filter\": \"summary,issuetype,creator,status\", # OPTIONAL: Comma-separated names of fields to extract from created ticket to output params }, \"retry_timeout_seconds\": 180, # OPTIONAL: Timeout for JIRA client operations in seconds (default: 180) \"retry_wait_seconds\": 1, # OPTIONAL: Wait interval between retries in seconds (default: 1) } Systems Configuration (expected in \"systems.jira\" block): { \"url\": \"https://your_cloud_jira.atlassian.net\", # REQUIRED: JIRA server URL \"username\": \"your_username_or_email\", # REQUIRED: JIRA user login or email \"password\": \"<your_token>\", # REQUIRED: JIRA user token \"auth_type\": \"basic\" # OPTIONAL: 'basic' or 'bearer' } Command name: \"jira-create-ticket\"","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;JiraCreateTicket"},{"location":"mkdocs/commands/#qubership_pipelines_common_library.v2.jira.jira_add_ticket_comment_command.JiraAddTicketComment","text":"JiraAddTicketComment(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Bases: ExecutionCommand Adds comment to JIRA ticket and retrieves latest comments. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"ticket\": { \"id\": \"BUG-567\", # REQUIRED: Ticket ID \"comment\": \"your comment body\", # REQUIRED: Comment body \"latest_comments_count\": 50, # OPTIONAL: Number of latest comments to fetch }, \"retry_timeout_seconds\": 180, # OPTIONAL: Timeout for JIRA client operations in seconds (default: 180) \"retry_wait_seconds\": 1, # OPTIONAL: Wait interval between retries in seconds (default: 1) } Systems Configuration (expected in \"systems.jira\" block): { \"url\": \"https://your_cloud_jira.atlassian.net\", # REQUIRED: JIRA server URL \"username\": \"your_username_or_email\", # REQUIRED: JIRA user login or email \"password\": \"<your_token>\", # REQUIRED: JIRA user token \"auth_type\": \"basic\" # OPTIONAL: 'basic' or 'bearer' } Command name: \"jira-add-ticket-comment\"","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;JiraAddTicketComment"},{"location":"mkdocs/commands/#qubership_pipelines_common_library.v2.jira.jira_update_ticket_command.JiraUpdateTicket","text":"JiraUpdateTicket(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Bases: ExecutionCommand Updates ticket fields and transitions status. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"ticket\": { \"fields: { # REQUIRED: Dict structure that will be used as ticket-update-body, without transformations \"status\": {\"name\": \"Done\"}, # OPTIONAL: Next status name \"transition\": {\"name\": \"From Review to Done\"}, # OPTIONAL: Transition name \"priority\": {\"name\": \"High\"}, # OPTIONAL: Other ticket fields with different formats, depending on your Project configuration \"duedate\": \"2030-02-20\", # OPTIONAL: Text-value fields need no dict wrappers \"description\": \"Ticket body\", \"labels\": [\"Test_Label1\"], }, \"id\": \"BUG-567\", # REQUIRED: Ticket ID \"comment\": \"your comment body\", # OPTIONAL: Comment to add to created ticket \"field_names_filter\": \"summary,issuetype,creator,status\", # OPTIONAL: Comma-separated names of fields to extract from created ticket to output params }, \"retry_timeout_seconds\": 180, # OPTIONAL: Timeout for JIRA client operations in seconds (default: 180) \"retry_wait_seconds\": 1, # OPTIONAL: Wait interval between retries in seconds (default: 1) } Systems Configuration (expected in \"systems.jira\" block): { \"url\": \"https://your_cloud_jira.atlassian.net\", # REQUIRED: JIRA server URL \"username\": \"your_username_or_email\", # REQUIRED: JIRA user login or email \"password\": \"<your_token>\", # REQUIRED: JIRA user token \"auth_type\": \"basic\" # OPTIONAL: 'basic' or 'bearer' } Command name: \"jira-update-ticket\"","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;JiraUpdateTicket"},{"location":"mkdocs/commands/#qubership_pipelines_common_library.v2.podman.podman_command.PodmanRunImage","text":"PodmanRunImage(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Bases: ExecutionCommand Executes a container using \"podman run\" command. This command supports running containers with configurable execution parameters, environment variable management, file mounting, and output extraction. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"image\": \"docker.io/library/hello-world:latest\", # REQUIRED: Container image to run \"command\": \"python -m pipelines_declarative_executor run --pipeline_dir=\"/WORK/EXEC_DIR\"\", # OPTIONAL: Command to execute in container \"execution_config\": { # ALL OF THESE ARE OPTIONAL \"working_dir\": \"/some/dir/inside/container\", # Working directory inside container \"timeout\": \"600\", # Maximum execution time in seconds \"operations_timeout\": \"15\", # Timeout for operations like file copying \"remove_container\": True, # Whether to remove container after execution \"save_stdout_to_logs\": True, # Save container stdout to execution logs \"save_stdout_to_files\": True, # Save container stdout to output files \"save_stdout_to_params\": False, # Save container stdout to output parameters \"expected_return_codes\": \"0,125\", # Comma-separated list of acceptable exit codes \"additional_run_flags\": \"--cgroups=disabled\", # Optional string of flags that will be added to \"podman run\" command }, \"before_script\": { \"mounts\": { # Filesystem mounts, \"host_path: container_path\" \"output_files\": \"/WORK\", \"prepared_data\": \"/CONFIGS\" }, \"env_vars\": { \"explicit\": { # Direct environment variable assignment \"PIPELINES_DECLARATIVE_EXECUTOR_ENCRYPT_OUTPUT_SECURE_PARAMS\": False }, \"env_files\": [ # Environment files on host to load and pass into container \"../CONFIGS/sample.env\" ], \"pass_via_file\": { # Sensitive vars passed via temp file \"SOMETHING_VERY_SECURE\": \"PASSWORD\" }, \"host_prefixes\": [ # Host environment variable prefixes to pass through. Can use \"*\" to pass everything from host. \"SOME_PREFIX_*\" ] } }, \"after_script\": { \"copy_files_to_host\": { # Copy files from container to host after execution, \"host_path: container_path\" \"output_files/report.json\": \"/WORK/EXEC_DIR/pipeline_state/pipeline_ui_view.json\", \"output_files/pipeline_state\": \"/WORK/EXEC_DIR/pipeline_state\", }, \"extract_params_from_files\": { # OPTIONAL: Extract parameters from container files. Supports JSON, YAML, and ENV files \"SOME_FILE_IN_CONTAINER\": \"SECTION_NAME_IN_PARAMS_WHERE_IT_WILL_BE_STORED\", } } } Output Parameters params.execution_time: Total execution time in seconds params.return_code: Container exit code params.stdout: Container stdout (if save_stdout_to_params enabled) params.stderr: Container stderr (if save_stdout_to_params enabled) params.extracted_output.*: Extracted parameters from files (if extract_params_from_files configured) Notes The command automatically handles container lifecycle including start, execution, and cleanup All host-paths (including mount paths) are resolved relative to context directory.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;PodmanRunImage"},{"location":"mkdocs/commands/#qubership_pipelines_common_library.v2.notifications.send_email_command.SendEmail","text":"SendEmail(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Bases: ExecutionCommand This command sends email notification with optional attachments. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"email_subject\": \"Report for 01.01.2026\", # REQUIRED: E-mail subject \"email_body\": \"Following jobs were completed: ...\", # REQUIRED: E-mail message \"email_recipients\": \"user1@qubership.org,user2@qubership.org\", # REQUIRED: Comma-separated list of recipients \"email_body_type\": \"plain\", # OPTIONAL: Either \"plain\" or \"html \"attachments\": { # OPTIONAL: Dict with attachments \"unique_attachment_key\": { \"name\": \"HTML_report.html\", # REQUIRED: File name used for attachment \"content\": \"<html>...</html>\", # REQUIRED: Text content put inside attachment \"mime_type\": \"text/html\", }, \"another_attachment_key\": {...} } } Systems Configuration (expected in \"systems.email\" block): { \"server\": \"your.mail.server.org\", # REQUIRED: E-mail host server \"port\": \"3025\" # REQUIRED: E-mail port \"user\": \"your@email.bot\" # REQUIRED: E-mail user \"password\": \"<email_password>\" # OPTIONAL: E-mail password \"use_ssl\": \"False\" # OPTIONAL: SMTP connection will use SSL mode (default: False) \"use_tls\": \"False\" # OPTIONAL: SMTP connection will use TLS mode (default: False) \"verify\": \"False\" # OPTIONAL: SSL Certificate verification (default: False) \"timeout_seconds\": \"60\" # OPTIONAL: SMTP connection timeout in seconds (default: 60) } Command name: \"send-email\"","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;SendEmail"},{"location":"mkdocs/commands/#qubership_pipelines_common_library.v2.notifications.send_webex_message_command.SendWebexMessage","text":"SendWebexMessage(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Bases: ExecutionCommand This command sends Webex message with optional attachments. Input Parameters Structure (this structure is expected inside \"input_params.params\" block): { \"webex_message\": \"Hello, world!\", # REQUIRED: Text message (Markdown format is supported) \"parent_id\": \"1234321\", # OPTIONAL: The parent message to reply to \"attachments\": { # OPTIONAL: Dict with attachments \"unique_attachment_key\": { \"name\": \"HTML_report.html\", # REQUIRED: File name used for attachment \"content\": \"<html>...</html>\", # REQUIRED: Text content put inside attachment \"mime_type\": \"text/html\", }, \"another_attachment_key\": {...} } } Systems Configuration (expected in \"systems.webex\" block): { \"room_id\": \"...Y2lzY29zc...\", # REQUIRED: Webex unique room_id where message will be posted \"token\": \"your_bot_account_token\" # REQUIRED: Bot/Service account token that will be used to send message \"proxy\": \"https://127.0.0.1\" # OPTIONAL: Host to be used as a webex-proxy } Output Parameters params.message_id: Received message_id of sent message params.attachment_message_ids: dict of attachment_name -> message_id Command name: \"send-webex-message\"","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;SendWebexMessage"},{"location":"mkdocs/context/","text":"ExecutionCommand ExecutionCommand(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Extendable interface intended to simplify working with input/output params and passing them between commands in different Pipeline Executors Implementations are expected to override _validate and _execute methods If context_path is not provided - context will be created dynamically using other provided params Parameters: context_path ( str , default: None ) \u2013 Path to context-describing yaml, that should contain references to input/output param file locations input_params ( dict , default: None ) \u2013 Non-secure parameters that will be merged into dynamically created params input_params_secure ( dict , default: None ) \u2013 Secure parameters that will be merged into dynamically created params folder_path ( str , default: None ) \u2013 Folder path where dynamically-created context will be stored. Optional, will create new temp folder if missing. parent_context_to_reuse ( ExecutionContext , default: None ) \u2013 Optional, existing context to propagate input params from. pre_execute_actions ( list [ ExecutionCommandExtension ] , default: None ) \u2013 Optional, list of actions, implementing ExecutionCommandExtension, to be executed before command post_execute_actions ( list [ ExecutionCommandExtension ] , default: None ) \u2013 Optional, list of actions, implementing ExecutionCommandExtension, to be executed after command run run() Runs command following its lifecycle ExecutionContext ExecutionContext(context_path: str ) Interface that provides references and shortcuts to navigating provided input params, storing any output params, and logging messages. Parameters: context_path ( str ) \u2013 Path to context-describing yaml, that should contain references to input/output param file locations output_params_save output_params_save() Stores output_param files to disk input_param_get input_param_get(path, def_value=None) Gets parameter from provided params files by its param path, supporting dot-separated nested keys (e.g. 'parent_obj.child_obj.param_name') output_param_set output_param_set(path, value) Sets param by path in non-secure output params output_param_secure_set output_param_secure_set(path, value) Sets param by path in secure output params validate validate(names, silent=False) Validates that all provided param names are present among provided param files ExecutionContextFile ExecutionContextFile(path=None) Interface to work with params and context files, used in ExecutionContext . Provides methods to init default content for different types of descriptors (e.g. init_context_descriptor , init_params ) init_empty init_empty() init_context_descriptor init_context_descriptor(context_folder_path: str = None) init_params init_params() init_params_secure init_params_secure() load load(path) Loads and validates file as one of supported types of descriptors save save(path) Writes current file content from memory to disk get get(path, def_value=None) Gets parameter from current file content by its param path, supporting dot-separated nested keys (e.g. 'parent_obj.child_obj.param_name') set set(path, value) Sets parameter in current file content set_multiple set_multiple(dict) Sets multiple parameters in current file content ExecutionInfo ExecutionInfo() Describes trackable running processes (e.g. triggered GitHub workflow) start start() Records start time for described process and transitions its status to IN_PROGRESS stop stop(status: str = None) Records finish time for described process, and optionally transitions its status to passed value get_duration get_duration() Returns duration of this process after it's finished get_duration_str get_duration_str() Returns formatted duration of this process as hh:mm:ss string after it's finished ExecutionLogger ExecutionLogger(path_logs) Default logger used by ExecutionCommands , implicitly initialized when using Context. Reference to it is available from instance of ExecutionContext . Provides common logging methods of different log levels - e.g. debug , info , error utils_cli utils_cli(func) Decorator to add CLI options for logging level, context path and custom input params. create_execution_context create_execution_context(input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None) Dynamically creates ExecutionContext using provided params. Parameters: input_params ( dict , default: None ) \u2013 dict (will be merged into created input params) input_params_secure ( dict , default: None ) \u2013 dict (will be merged into created secure input params) folder_path ( str , default: None ) \u2013 str (optional, will generate new temp) parent_context_to_reuse ( ExecutionContext , default: None ) \u2013 ExecutionContext (optional, to propagate existing input params)","title":"Context"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_command.ExecutionCommand","text":"ExecutionCommand(context_path: str = None, input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None, pre_execute_actions: list [ ExecutionCommandExtension ] = None, post_execute_actions: list [ ExecutionCommandExtension ] = None) Extendable interface intended to simplify working with input/output params and passing them between commands in different Pipeline Executors Implementations are expected to override _validate and _execute methods If context_path is not provided - context will be created dynamically using other provided params Parameters: context_path ( str , default: None ) \u2013 Path to context-describing yaml, that should contain references to input/output param file locations input_params ( dict , default: None ) \u2013 Non-secure parameters that will be merged into dynamically created params input_params_secure ( dict , default: None ) \u2013 Secure parameters that will be merged into dynamically created params folder_path ( str , default: None ) \u2013 Folder path where dynamically-created context will be stored. Optional, will create new temp folder if missing. parent_context_to_reuse ( ExecutionContext , default: None ) \u2013 Optional, existing context to propagate input params from. pre_execute_actions ( list [ ExecutionCommandExtension ] , default: None ) \u2013 Optional, list of actions, implementing ExecutionCommandExtension, to be executed before command post_execute_actions ( list [ ExecutionCommandExtension ] , default: None ) \u2013 Optional, list of actions, implementing ExecutionCommandExtension, to be executed after command","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;ExecutionCommand"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_command.ExecutionCommand.run","text":"run() Runs command following its lifecycle","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;run"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context.ExecutionContext","text":"ExecutionContext(context_path: str ) Interface that provides references and shortcuts to navigating provided input params, storing any output params, and logging messages. Parameters: context_path ( str ) \u2013 Path to context-describing yaml, that should contain references to input/output param file locations","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;ExecutionContext"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context.ExecutionContext.output_params_save","text":"output_params_save() Stores output_param files to disk","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;output_params_save"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context.ExecutionContext.input_param_get","text":"input_param_get(path, def_value=None) Gets parameter from provided params files by its param path, supporting dot-separated nested keys (e.g. 'parent_obj.child_obj.param_name')","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;input_param_get"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context.ExecutionContext.output_param_set","text":"output_param_set(path, value) Sets param by path in non-secure output params","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;output_param_set"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context.ExecutionContext.output_param_secure_set","text":"output_param_secure_set(path, value) Sets param by path in secure output params","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;output_param_secure_set"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context.ExecutionContext.validate","text":"validate(names, silent=False) Validates that all provided param names are present among provided param files","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;validate"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context_file.ExecutionContextFile","text":"ExecutionContextFile(path=None) Interface to work with params and context files, used in ExecutionContext . Provides methods to init default content for different types of descriptors (e.g. init_context_descriptor , init_params )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;ExecutionContextFile"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context_file.ExecutionContextFile.init_empty","text":"init_empty()","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;init_empty"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context_file.ExecutionContextFile.init_context_descriptor","text":"init_context_descriptor(context_folder_path: str = None)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;init_context_descriptor"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context_file.ExecutionContextFile.init_params","text":"init_params()","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;init_params"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context_file.ExecutionContextFile.init_params_secure","text":"init_params_secure()","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;init_params_secure"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context_file.ExecutionContextFile.load","text":"load(path) Loads and validates file as one of supported types of descriptors","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;load"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context_file.ExecutionContextFile.save","text":"save(path) Writes current file content from memory to disk","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;save"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context_file.ExecutionContextFile.get","text":"get(path, def_value=None) Gets parameter from current file content by its param path, supporting dot-separated nested keys (e.g. 'parent_obj.child_obj.param_name')","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context_file.ExecutionContextFile.set","text":"set(path, value) Sets parameter in current file content","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;set"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_context_file.ExecutionContextFile.set_multiple","text":"set_multiple(dict) Sets multiple parameters in current file content","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;set_multiple"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_info.ExecutionInfo","text":"ExecutionInfo() Describes trackable running processes (e.g. triggered GitHub workflow)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;ExecutionInfo"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_info.ExecutionInfo.start","text":"start() Records start time for described process and transitions its status to IN_PROGRESS","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;start"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_info.ExecutionInfo.stop","text":"stop(status: str = None) Records finish time for described process, and optionally transitions its status to passed value","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;stop"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_info.ExecutionInfo.get_duration","text":"get_duration() Returns duration of this process after it's finished","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_duration"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_info.ExecutionInfo.get_duration_str","text":"get_duration_str() Returns formatted duration of this process as hh:mm:ss string after it's finished","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_duration_str"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.execution.exec_logger.ExecutionLogger","text":"ExecutionLogger(path_logs) Default logger used by ExecutionCommands , implicitly initialized when using Context. Reference to it is available from instance of ExecutionContext . Provides common logging methods of different log levels - e.g. debug , info , error","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;ExecutionLogger"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.utils.utils_cli.utils_cli","text":"utils_cli(func) Decorator to add CLI options for logging level, context path and custom input params.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;utils_cli"},{"location":"mkdocs/context/#qubership_pipelines_common_library.v1.utils.utils_context.create_execution_context","text":"create_execution_context(input_params: dict = None, input_params_secure: dict = None, folder_path: str = None, parent_context_to_reuse: ExecutionContext = None) Dynamically creates ExecutionContext using provided params. Parameters: input_params ( dict , default: None ) \u2013 dict (will be merged into created input params) input_params_secure ( dict , default: None ) \u2013 dict (will be merged into created secure input params) folder_path ( str , default: None ) \u2013 str (optional, will generate new temp) parent_context_to_reuse ( ExecutionContext , default: None ) \u2013 ExecutionContext (optional, to propagate existing input params)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;create_execution_context"}]}